import os
from dataset.mask import get_person_semantics_mask
import torch
import math
import torch.nn as nn
from dataset.transforms import build_transforms_mask


def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        print("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",)

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor


def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    # type: (Tensor, float, float, float, float) -> Tensor
    r"""Fills the input Tensor with values drawn from a truncated
    normal distribution. The values are effectively drawn from the
    normal distribution :math:`\mathcal{N}(\text{mean}, \text{std}^2)`
    with values outside :math:`[a, b]` redrawn until they are within
    the bounds. The method used for generating the random values works
    best when :math:`a \leq \text{mean} \leq b`.
    Args:
        tensor: an n-dimensional `torch.Tensor`
        mean: the mean of the normal distribution
        std: the standard deviation of the normal distribution
        a: the minimum cutoff value
        b: the maximum cutoff value
    Examples:
        >>> w = torch.empty(3, 5)
        >>> nn.init.trunc_normal_(w)
    """
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)

if __name__ == '__main__':
    # initialize Embeding Information
    embed_dim = 768
    # transforms
    trans = build_transforms_mask()
    # process MSMT Mask
    dirs_mask = {'../dataset/LTCC_ReID/train-mask','../dataset/LTCC_ReID/test-mask','../dataset/LTCC_ReID/query-mask'}
    dir_output = '../dataset/LTCC_ReID/vit_patch_mask'
    if not os.path.exists(dir_output):
        os.mkdir(dir_output)
    # 
    num_y = 21
    num_x = 10
    stride_size = (12,12)
    patch_size = (16,16)
    for dir_mask in dirs_mask:
        print(f'processing dir: {dir_mask}')
        files_mask = os.listdir(dir_mask)
        for i,file in enumerate(files_mask):
            print(f'\rprocessing files [{i+1}/{len(files_mask)}]: {file}',end='')
            file_path = os.path.join(dir_mask,file)
            output_path = os.path.join(dir_output,file.split('.')[0]+'.pt')
            mask = get_person_semantics_mask(file_path)
            mask = torch.from_numpy(mask)
            mask = mask.unsqueeze(0)
            mask = trans(mask)
            mask = mask.squeeze(0)


            mask_ids = torch.zeros(num_y, num_x)
            #mask_embed_in = torch.zeros(embed_dim, num_y, num_x)
            for i in range(0,num_y):
                for j in range(0, num_x):
                    i_b = i*stride_size[0]
                    i_e = i*stride_size[0]+patch_size[0]
                    j_b = j*stride_size[1]
                    j_e = j*stride_size[1]+patch_size[1]
                    count = torch.bincount(mask[i_b:i_e,j_b:j_e].reshape(-1))
                    mask_id = torch.argmax(count)
                    if mask_id == 0 and len(count) > 1:
                        # flag patch to background label only if pixels in this patch are all background
                        mask_id = torch.argmax(count[1:]) + 1
                    mask_ids[i,j] = mask_id 
            torch.save(mask_ids,output_path)
    

            